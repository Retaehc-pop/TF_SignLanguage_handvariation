{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA preprocessing and create lable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as pyplot\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(\"DATA\") # paht of the exported data\n",
    "alphabet = string.ascii_lowercase+string.digits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "character,lables = [], []\n",
    "alphabet = np.array(os.listdir(os.path.join(DATA_PATH)))\n",
    "label_map = {lable:num for num,lable in enumerate(alphabet)}\n",
    "for char in alphabet:\n",
    "  for files in os.listdir(os.path.join(DATA_PATH,char)):\n",
    "    res = np.load(os.path.join(DATA_PATH,char,files))\n",
    "    character.append(res)\n",
    "    lables.append(label_map[char])\n",
    "\n",
    "X = np.array(character)\n",
    "y = to_categorical(lables).astype(int)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7489, 63)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense,Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "235/235 [==============================] - 3s 6ms/step - loss: 2.9740 - categorical_accuracy: 0.0995\n",
      "Epoch 2/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 2.1932 - categorical_accuracy: 0.2505\n",
      "Epoch 3/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.6325 - categorical_accuracy: 0.4001\n",
      "Epoch 4/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 1.2744 - categorical_accuracy: 0.5242\n",
      "Epoch 5/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.9912 - categorical_accuracy: 0.6205\n",
      "Epoch 6/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.7721 - categorical_accuracy: 0.7130\n",
      "Epoch 7/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.6419 - categorical_accuracy: 0.7612\n",
      "Epoch 8/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.6034 - categorical_accuracy: 0.7686\n",
      "Epoch 9/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.5447 - categorical_accuracy: 0.7913\n",
      "Epoch 10/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.5053 - categorical_accuracy: 0.8050\n",
      "Epoch 11/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4494 - categorical_accuracy: 0.8289\n",
      "Epoch 12/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4219 - categorical_accuracy: 0.8334\n",
      "Epoch 13/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3935 - categorical_accuracy: 0.8500\n",
      "Epoch 14/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3856 - categorical_accuracy: 0.8503\n",
      "Epoch 15/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3428 - categorical_accuracy: 0.8654\n",
      "Epoch 16/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3604 - categorical_accuracy: 0.8611\n",
      "Epoch 17/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3165 - categorical_accuracy: 0.8780\n",
      "Epoch 18/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3556 - categorical_accuracy: 0.8642\n",
      "Epoch 19/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3065 - categorical_accuracy: 0.8814\n",
      "Epoch 20/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2629 - categorical_accuracy: 0.8997\n",
      "Epoch 21/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2506 - categorical_accuracy: 0.9067\n",
      "Epoch 22/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2614 - categorical_accuracy: 0.8993\n",
      "Epoch 23/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2634 - categorical_accuracy: 0.8988\n",
      "Epoch 24/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2825 - categorical_accuracy: 0.8929\n",
      "Epoch 25/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2160 - categorical_accuracy: 0.9159\n",
      "Epoch 26/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2467 - categorical_accuracy: 0.9071\n",
      "Epoch 27/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2195 - categorical_accuracy: 0.9157\n",
      "Epoch 28/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2160 - categorical_accuracy: 0.9165\n",
      "Epoch 29/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2047 - categorical_accuracy: 0.9228\n",
      "Epoch 30/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2494 - categorical_accuracy: 0.9155\n",
      "Epoch 31/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2035 - categorical_accuracy: 0.9204\n",
      "Epoch 32/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1901 - categorical_accuracy: 0.9292\n",
      "Epoch 33/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2058 - categorical_accuracy: 0.9214\n",
      "Epoch 34/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2169 - categorical_accuracy: 0.9179\n",
      "Epoch 35/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1834 - categorical_accuracy: 0.9312\n",
      "Epoch 36/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1961 - categorical_accuracy: 0.9240\n",
      "Epoch 37/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1965 - categorical_accuracy: 0.9263\n",
      "Epoch 38/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1853 - categorical_accuracy: 0.9319\n",
      "Epoch 39/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1607 - categorical_accuracy: 0.9391\n",
      "Epoch 40/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1672 - categorical_accuracy: 0.9386\n",
      "Epoch 41/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1898 - categorical_accuracy: 0.9314\n",
      "Epoch 42/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1445 - categorical_accuracy: 0.9465\n",
      "Epoch 43/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1795 - categorical_accuracy: 0.9326\n",
      "Epoch 44/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1978 - categorical_accuracy: 0.9263\n",
      "Epoch 45/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1516 - categorical_accuracy: 0.9453\n",
      "Epoch 46/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1655 - categorical_accuracy: 0.9406\n",
      "Epoch 47/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1891 - categorical_accuracy: 0.9340\n",
      "Epoch 48/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1689 - categorical_accuracy: 0.9364\n",
      "Epoch 49/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1535 - categorical_accuracy: 0.9431\n",
      "Epoch 50/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1439 - categorical_accuracy: 0.9457\n",
      "Epoch 51/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1396 - categorical_accuracy: 0.9511\n",
      "Epoch 52/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1320 - categorical_accuracy: 0.9542\n",
      "Epoch 53/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1474 - categorical_accuracy: 0.9455\n",
      "Epoch 54/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1511 - categorical_accuracy: 0.9438\n",
      "Epoch 55/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1664 - categorical_accuracy: 0.9368\n",
      "Epoch 56/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1518 - categorical_accuracy: 0.9467\n",
      "Epoch 57/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1654 - categorical_accuracy: 0.9398\n",
      "Epoch 58/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1648 - categorical_accuracy: 0.9408\n",
      "Epoch 59/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1479 - categorical_accuracy: 0.9446\n",
      "Epoch 60/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1408 - categorical_accuracy: 0.9491\n",
      "Epoch 61/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1301 - categorical_accuracy: 0.9533\n",
      "Epoch 62/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1477 - categorical_accuracy: 0.9451\n",
      "Epoch 63/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1382 - categorical_accuracy: 0.9491\n",
      "Epoch 64/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1797 - categorical_accuracy: 0.9348\n",
      "Epoch 65/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.2722 - categorical_accuracy: 0.9163\n",
      "Epoch 66/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1462 - categorical_accuracy: 0.9453\n",
      "Epoch 67/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0998 - categorical_accuracy: 0.9637\n",
      "Epoch 68/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1049 - categorical_accuracy: 0.9607\n",
      "Epoch 69/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1634 - categorical_accuracy: 0.9435\n",
      "Epoch 70/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1243 - categorical_accuracy: 0.9545\n",
      "Epoch 71/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1159 - categorical_accuracy: 0.9578\n",
      "Epoch 72/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1655 - categorical_accuracy: 0.9419\n",
      "Epoch 73/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1041 - categorical_accuracy: 0.9649\n",
      "Epoch 74/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1076 - categorical_accuracy: 0.9623\n",
      "Epoch 75/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1325 - categorical_accuracy: 0.9510\n",
      "Epoch 76/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1619 - categorical_accuracy: 0.9426\n",
      "Epoch 77/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0965 - categorical_accuracy: 0.9673\n",
      "Epoch 78/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1256 - categorical_accuracy: 0.9569\n",
      "Epoch 79/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0883 - categorical_accuracy: 0.9681\n",
      "Epoch 80/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1472 - categorical_accuracy: 0.9475\n",
      "Epoch 81/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1348 - categorical_accuracy: 0.9507\n",
      "Epoch 82/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1086 - categorical_accuracy: 0.9634\n",
      "Epoch 83/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1225 - categorical_accuracy: 0.9561\n",
      "Epoch 84/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2399 - categorical_accuracy: 0.9274\n",
      "Epoch 85/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0970 - categorical_accuracy: 0.9664\n",
      "Epoch 86/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1000 - categorical_accuracy: 0.9634\n",
      "Epoch 87/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0977 - categorical_accuracy: 0.9674\n",
      "Epoch 88/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1152 - categorical_accuracy: 0.9586\n",
      "Epoch 89/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1072 - categorical_accuracy: 0.9621\n",
      "Epoch 90/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1066 - categorical_accuracy: 0.9626\n",
      "Epoch 91/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0834 - categorical_accuracy: 0.9688\n",
      "Epoch 92/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1369 - categorical_accuracy: 0.9526\n",
      "Epoch 93/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1113 - categorical_accuracy: 0.9590\n",
      "Epoch 94/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1047 - categorical_accuracy: 0.9617\n",
      "Epoch 95/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1260 - categorical_accuracy: 0.9539\n",
      "Epoch 96/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1096 - categorical_accuracy: 0.9595\n",
      "Epoch 97/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1032 - categorical_accuracy: 0.9658\n",
      "Epoch 98/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0992 - categorical_accuracy: 0.9666\n",
      "Epoch 99/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1209 - categorical_accuracy: 0.9578\n",
      "Epoch 100/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1250 - categorical_accuracy: 0.9589\n",
      "Epoch 101/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1108 - categorical_accuracy: 0.9605\n",
      "Epoch 102/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1163 - categorical_accuracy: 0.9570\n",
      "Epoch 103/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0985 - categorical_accuracy: 0.9629\n",
      "Epoch 104/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1107 - categorical_accuracy: 0.9577\n",
      "Epoch 105/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1068 - categorical_accuracy: 0.9649\n",
      "Epoch 106/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1150 - categorical_accuracy: 0.9573\n",
      "Epoch 107/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0923 - categorical_accuracy: 0.9666\n",
      "Epoch 108/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1300 - categorical_accuracy: 0.9542\n",
      "Epoch 109/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1090 - categorical_accuracy: 0.9593\n",
      "Epoch 110/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0790 - categorical_accuracy: 0.9716\n",
      "Epoch 111/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1368 - categorical_accuracy: 0.9503\n",
      "Epoch 112/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0964 - categorical_accuracy: 0.9677\n",
      "Epoch 113/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0799 - categorical_accuracy: 0.9708\n",
      "Epoch 114/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0810 - categorical_accuracy: 0.9717\n",
      "Epoch 115/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0911 - categorical_accuracy: 0.9668\n",
      "Epoch 116/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1227 - categorical_accuracy: 0.9546\n",
      "Epoch 117/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0840 - categorical_accuracy: 0.9704\n",
      "Epoch 118/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0740 - categorical_accuracy: 0.9724\n",
      "Epoch 119/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1173 - categorical_accuracy: 0.9582\n",
      "Epoch 120/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1034 - categorical_accuracy: 0.9657\n",
      "Epoch 121/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0799 - categorical_accuracy: 0.9713\n",
      "Epoch 122/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0677 - categorical_accuracy: 0.9762\n",
      "Epoch 123/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1233 - categorical_accuracy: 0.9538\n",
      "Epoch 124/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1006 - categorical_accuracy: 0.9653\n",
      "Epoch 125/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1001 - categorical_accuracy: 0.9641\n",
      "Epoch 126/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0990 - categorical_accuracy: 0.9641\n",
      "Epoch 127/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0613 - categorical_accuracy: 0.9794\n",
      "Epoch 128/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0729 - categorical_accuracy: 0.9742\n",
      "Epoch 129/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1030 - categorical_accuracy: 0.9654\n",
      "Epoch 130/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0919 - categorical_accuracy: 0.9688\n",
      "Epoch 131/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0933 - categorical_accuracy: 0.9684\n",
      "Epoch 132/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1356 - categorical_accuracy: 0.9515\n",
      "Epoch 133/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0736 - categorical_accuracy: 0.9752\n",
      "Epoch 134/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0811 - categorical_accuracy: 0.9709\n",
      "Epoch 135/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0936 - categorical_accuracy: 0.9698\n",
      "Epoch 136/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1045 - categorical_accuracy: 0.9639\n",
      "Epoch 137/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4516 - categorical_accuracy: 0.8925\n",
      "Epoch 138/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0863 - categorical_accuracy: 0.9706\n",
      "Epoch 139/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0624 - categorical_accuracy: 0.9796\n",
      "Epoch 140/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0714 - categorical_accuracy: 0.9740\n",
      "Epoch 141/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0735 - categorical_accuracy: 0.9744\n",
      "Epoch 142/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.4200 - categorical_accuracy: 0.9055\n",
      "Epoch 143/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0863 - categorical_accuracy: 0.9702\n",
      "Epoch 144/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0811 - categorical_accuracy: 0.9736\n",
      "Epoch 145/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0895 - categorical_accuracy: 0.9662\n",
      "Epoch 146/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0756 - categorical_accuracy: 0.9754\n",
      "Epoch 147/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0655 - categorical_accuracy: 0.9760\n",
      "Epoch 148/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0686 - categorical_accuracy: 0.9758\n",
      "Epoch 149/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0811 - categorical_accuracy: 0.9712\n",
      "Epoch 150/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0887 - categorical_accuracy: 0.9697\n",
      "Epoch 151/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0618 - categorical_accuracy: 0.9766\n",
      "Epoch 152/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1088 - categorical_accuracy: 0.9625\n",
      "Epoch 153/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0643 - categorical_accuracy: 0.9766\n",
      "Epoch 154/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0941 - categorical_accuracy: 0.9688\n",
      "Epoch 155/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0860 - categorical_accuracy: 0.9680\n",
      "Epoch 156/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0832 - categorical_accuracy: 0.9706\n",
      "Epoch 157/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1032 - categorical_accuracy: 0.9650\n",
      "Epoch 158/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0773 - categorical_accuracy: 0.9748\n",
      "Epoch 159/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0693 - categorical_accuracy: 0.9757\n",
      "Epoch 160/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0951 - categorical_accuracy: 0.9664\n",
      "Epoch 161/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0746 - categorical_accuracy: 0.9730\n",
      "Epoch 162/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0598 - categorical_accuracy: 0.9790\n",
      "Epoch 163/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1001 - categorical_accuracy: 0.9660\n",
      "Epoch 164/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0619 - categorical_accuracy: 0.9788\n",
      "Epoch 165/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0528 - categorical_accuracy: 0.9821\n",
      "Epoch 166/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1363 - categorical_accuracy: 0.9547\n",
      "Epoch 167/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0657 - categorical_accuracy: 0.9782\n",
      "Epoch 168/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0577 - categorical_accuracy: 0.9788\n",
      "Epoch 169/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0925 - categorical_accuracy: 0.9686\n",
      "Epoch 170/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0592 - categorical_accuracy: 0.9797\n",
      "Epoch 171/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1138 - categorical_accuracy: 0.9621\n",
      "Epoch 172/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0892 - categorical_accuracy: 0.9681\n",
      "Epoch 173/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0843 - categorical_accuracy: 0.9732\n",
      "Epoch 174/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0548 - categorical_accuracy: 0.9793\n",
      "Epoch 175/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0614 - categorical_accuracy: 0.9798\n",
      "Epoch 176/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2646 - categorical_accuracy: 0.9252\n",
      "Epoch 177/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0560 - categorical_accuracy: 0.9814\n",
      "Epoch 178/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0453 - categorical_accuracy: 0.9849\n",
      "Epoch 179/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0387 - categorical_accuracy: 0.9861\n",
      "Epoch 180/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0603 - categorical_accuracy: 0.9790\n",
      "Epoch 181/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1127 - categorical_accuracy: 0.9655\n",
      "Epoch 182/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0643 - categorical_accuracy: 0.9774\n",
      "Epoch 183/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0927 - categorical_accuracy: 0.9676\n",
      "Epoch 184/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0541 - categorical_accuracy: 0.9818\n",
      "Epoch 185/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0507 - categorical_accuracy: 0.9829\n",
      "Epoch 186/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0779 - categorical_accuracy: 0.9733\n",
      "Epoch 187/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0985 - categorical_accuracy: 0.9677\n",
      "Epoch 188/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0654 - categorical_accuracy: 0.9788\n",
      "Epoch 189/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0714 - categorical_accuracy: 0.9770\n",
      "Epoch 190/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0513 - categorical_accuracy: 0.9825\n",
      "Epoch 191/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0380 - categorical_accuracy: 0.9865\n",
      "Epoch 192/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0723 - categorical_accuracy: 0.9752\n",
      "Epoch 193/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0662 - categorical_accuracy: 0.9770\n",
      "Epoch 194/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0597 - categorical_accuracy: 0.9809\n",
      "Epoch 195/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0838 - categorical_accuracy: 0.9717\n",
      "Epoch 196/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0709 - categorical_accuracy: 0.9780\n",
      "Epoch 197/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0573 - categorical_accuracy: 0.9789\n",
      "Epoch 198/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0762 - categorical_accuracy: 0.9746\n",
      "Epoch 199/200\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.2241 - categorical_accuracy: 0.9443\n",
      "Epoch 200/200\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0566 - categorical_accuracy: 0.9796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ee06c8ccc8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64,activation=\"tanh\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(32,activation=\"relu\"))\n",
    "model.add(Dense(32,activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dense(alphabet.shape[0],activation=\"softmax\"))\n",
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
    "model.fit(X_train,y_train,epochs=200,callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                4096      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 25)                1625      \n",
      "=================================================================\n",
      "Total params: 10,969\n",
      "Trainable params: 10,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"action.h5\")\n",
    "# tfjs.converters.save_keras_model(model, \"tfjs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix,accuracy_score\n",
    "yhat = model.predict(X_test)\n",
    "ytrue = np.argmax(y_test,axis=1).tolist()\n",
    "yhat = np.argmax(yhat,axis=1).tolist()\n",
    "multilabel_confusion_matrix(ytrue,yhat)\n",
    "accuracy_score(ytrue,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils # drawing utilities\n",
    "\n",
    "def mediapipe_detection(image,model):\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # color conversion\n",
    "  image = cv2.flip(image, 1)\n",
    "  image.flags.writeable = False\n",
    "  results = model.process(image) # process image\n",
    "  image.flags.writeable = True\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # color conversion\n",
    "  return image,results\n",
    "\n",
    "def draw_landmarks(image,result):\n",
    "  if result.multi_hand_landmarks:\n",
    "    for num,hand in enumerate(result.multi_hand_landmarks):\n",
    "      mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS, \n",
    "                                mp_drawing.DrawingSpec(color=(0, 112, 255), thickness=1, circle_radius=2),\n",
    "                                mp_drawing.DrawingSpec(color=(255, 255, 0), thickness=2, circle_radius=4),\n",
    "                                )\n",
    "def extract_keypoint(result):\n",
    "  if result.multi_hand_landmarks:\n",
    "    for hand_landmarks in result.multi_hand_landmarks:\n",
    "      all_hand_pos = []\n",
    "      for joint in mp_hands.HandLandmark:\n",
    "        all_hand_pos.append(np.array([hand_landmarks.landmark[joint].x,hand_landmarks.landmark[joint].y,hand_landmarks.landmark[joint].z]))\n",
    "  else:\n",
    "    return np.zeros(21*3)\n",
    "  return np.concatenate(all_hand_pos) # return 63 point of connection\n",
    "\n",
    "colors = [(245,117,16), (117,245,16), (16,117,245),(44,217,235)]\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. New detection variables\n",
    "sequence = []\n",
    "word = []\n",
    "prob = []\n",
    "threshold = 0.95\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.5,max_num_hands=1) as hands:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, hands)\n",
    "        # Draw landmarks\n",
    "        draw_landmarks(image, results)\n",
    "        # 2. Prediction logic\n",
    "        keypoints = extract_keypoint(results)\n",
    "        sequence = keypoints\n",
    "        res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "        if res[np.argmax(res)] > threshold:\n",
    "            if len(prob) ==10 and all(x==prob[0] for x in prob):\n",
    "                prob=[]\n",
    "                if len(word)>0:\n",
    "                    if alphabet[np.argmax(res)] != word[-1]:\n",
    "                        word.append(alphabet[np.argmax(res)])\n",
    "                else:\n",
    "                    word.append(alphabet[np.argmax(res)])\n",
    "            else:\n",
    "                prob.append(alphabet[np.argmax(res)])\n",
    "                if len(prob)>=10:\n",
    "                    prob = prob[-10:]\n",
    "\n",
    "        if len(word) > 10: \n",
    "                word = word[-10:]\n",
    "        \n",
    "        # Viz probabilities\n",
    "        # image = prob_viz(res, actions, image, colors)\n",
    "            \n",
    "        cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, ''.join(word), (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9103b89518c9592aaf7b51401b88ec12ced5e1cde478347da803a0f3bed09c08"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('tf37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
